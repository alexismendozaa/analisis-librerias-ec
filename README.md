# ğŸ“š Sistema de AnÃ¡lisis de LibrerÃ­as por Provincia (Dataset SRI)

Un sistema inteligente con **scrapers integrados** que analiza datos del SRI para identificar, mapear y estudiar librerÃ­as por provincia, extrayendo catÃ¡logos de libros desde mÃºltiples fuentes (web, DuckDuckGo, Facebook) con anÃ¡lisis de IA mediante Groq.

---

## ğŸ¯ CaracterÃ­sticas Principales

âœ¨ **AnÃ¡lisis Completo de LibrerÃ­as**
- DetecciÃ³n automÃ¡tica de librerÃ­as usando CIIU y anÃ¡lisis de nombres
- Filtrado estricto por provincia con validaciÃ³n geogrÃ¡fica
- CÃ¡lculo de mÃ©tricas estadÃ­sticas detalladas

ğŸ—ºï¸ **VisualizaciÃ³n Geoespacial Precisa**
- GeocodificaciÃ³n con Geoapify usando cantÃ³n y parroquia
- ValidaciÃ³n estricta: solo muestra librerÃ­as de la provincia seleccionada
- Mapas interactivos con Folium y marcadores detallados

ğŸ“– **Scraping Multi-Fuente de CatÃ¡logos**
- **Nivel 1:** Web scraping directo desde sitios oficiales
- **Nivel 2:** Scraper Google integrado (DuckDuckGo - sin API key)
- **Nivel 3:** Scraper Facebook con Selenium + Groq AI
- **Nivel 4:** Fallback con catÃ¡logo simulado realista
- Sistema en cascada: intenta cada fuente hasta obtener resultados

ğŸ¤– **AnÃ¡lisis con IA (Groq)**
- Explicaciones inteligentes sobre best-sellers
- AnÃ¡lisis de factores de mercado local
- EvaluaciÃ³n de riesgos de piraterÃ­a
- ResÃºmenes automÃ¡ticos del ecosistema editorial

---

## ğŸ“‹ Requisitos Previos

### Sistema Operativo
- macOS, Linux o Windows
- Python 3.8 o superior

### Credenciales Necesarias
1. **API Key de Geoapify** - Para geocodificaciÃ³n
   - ObtÃ©n una en: [geoapify.com](https://www.geoapify.com/)
   - CrÃ©ditos gratuitos disponibles

2. **API Key de Groq** - Para anÃ¡lisis con IA
   - ObtÃ©n una en: [console.groq.com](https://console.groq.com/)
   - Modelo usado: `llama-3.3-70b-versatile`

3. **Dataset SRI**
   - Archivo CSV con columnas requeridas:
     - `NOMBRE_FANTASIA_COMERCIAL`
     - `DESCRIPCION_PROVINCIA_EST`
     - `DESCRIPCION_CANTON_EST`
     - `DESCRIPCION_PARROQUIA_EST`
     - Otras columnas de ubicaciÃ³n (detectadas automÃ¡ticamente)

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Clonar el Repositorio
```bash
git clone https://github.com/tuusuario/completo.git
cd completo
```

### 2. Crear Entorno Virtual
```bash
python3 -m venv venv
source venv/bin/activate  # En macOS/Linux
# o para Windows: venv\Scripts\activate
```

### 3. Instalar Dependencias
```bash
pip install -r requirements.txt
```

**Dependencias principales:**
- `streamlit` - Interfaz web
- `pandas` - Procesamiento de datos
- `requests` + `beautifulsoup4` - Web scraping
- `folium` + `branca` - Mapas interactivos
- `groq` - AnÃ¡lisis con IA
- `selenium` + `webdriver-manager` - Scraping dinÃ¡mico (Facebook)
- `unidecode` - NormalizaciÃ³n de texto

### 4. Configurar Variables de Entorno (Opcional)

Las API Keys se pueden configurar de dos formas:

#### OpciÃ³n A: Variables de Entorno (Recomendado)

**En macOS/Linux:**
```bash
export GEOAPIFY_KEY="tu_clave_aqui"
export GROQ_API_KEY="tu_clave_aqui"
streamlit run main.py
```

**En Windows (PowerShell):**
```powershell
$env:GEOAPIFY_KEY="tu_clave_aqui"
$env:GROQ_API_KEY="tu_clave_aqui"
streamlit run main.py
```

**En Windows (CMD):**
```cmd
set GEOAPIFY_KEY=tu_clave_aqui
set GROQ_API_KEY=tu_clave_aqui
streamlit run main.py
```

#### OpciÃ³n B: Interfaz Web (MÃ¡s flexible)
Si no configuras variables de entorno, la aplicaciÃ³n te pedirÃ¡ las claves directamente en la interfaz cuando la ejecutes.

---

## ğŸ’» EjecuciÃ³n

### Iniciar la AplicaciÃ³n Streamlit

En el terminal, desde la carpeta del proyecto:

```bash
streamlit run main.py
```

La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en `http://localhost:8501`

**Nota:** AsegÃºrate de que tu entorno virtual (`venv`) estÃ© activado antes de ejecutar el comando.

---

## ğŸ“– GuÃ­a de Uso

### Paso 1: Cargar Dataset
1. Haz clic en **"Subir archivo CSV"**
2. Selecciona tu archivo CSV del SRI
3. El sistema detectarÃ¡ automÃ¡ticamente el separador (`,`, `;`, `|`, etc.)

### Paso 2: Ingresar Credenciales
- **API Key de Geoapify**: Ingresa tu clave para geocodificaciÃ³n
- **API Key de Groq**: Ingresa tu clave para anÃ¡lisis de IA

### Paso 3: Seleccionar Provincia
1. Elige la provincia a analizar del dropdown
2. El sistema mostrarÃ¡:
   - Cantidad de librerÃ­as detectadas
   - Cantones y parroquias con presencia

### Paso 4: Analizar Datos
La aplicaciÃ³n ejecutarÃ¡ automÃ¡ticamente:
1. **DetecciÃ³n de librerÃ­as** - Identifica negocios del rubro
2. **GeocodificaciÃ³n** - Obtiene coordenadas precisas
3. **EstadÃ­sticas** - Calcula mÃ©tricas de distribuciÃ³n
4. **Mapa interactivo** - Visualiza ubicaciones en tiempo real

### Paso 5: ExtracciÃ³n de CatÃ¡logos (AutomÃ¡tico)
El sistema **extrae automÃ¡ticamente** catÃ¡logos de libros intentando mÃºltiples fuentes:

**Para cada librerÃ­a detectada:**
1. âœ… **Web scraping directo** - Busca en Google y extrae del sitio oficial
2. âœ… **Scraper Google (DuckDuckGo)** - BÃºsqueda sin lÃ­mites de API
3. âœ… **Scraper Facebook** - Extrae posts con tÃ­tulos de libros usando Selenium + IA
4. âœ… **Fallback simulado** - Genera catÃ¡logo realista si fallan todas las fuentes

**Resultado:** Ranking de los 15 libros mÃ¡s repetidos entre todas las librerÃ­as.

### Paso 6: AnÃ¡lisis con IA (Groq)
El sistema genera automÃ¡ticamente:
- ğŸ“– **ExplicaciÃ³n de best-sellers** - Por quÃ© ciertos tÃ­tulos dominan el mercado
- ğŸ“Š **AnÃ¡lisis de mercado local** - Factores econÃ³micos y culturales
- âš ï¸ **EvaluaciÃ³n de piraterÃ­a** - Riesgos por tÃ­tulo y provincia
- ğŸ“ **Resumen integral** - Insights sobre el ecosistema editorial

---

## ğŸ“ Estructura del Proyecto

```
completo/
â”œâ”€â”€ main.py                  # AplicaciÃ³n principal Streamlit
â”œâ”€â”€ data_processing.py       # Procesamiento de datos + web scraping
â”œâ”€â”€ scraper_google.py        # Scraper DuckDuckGo integrado (sin API key)
â”œâ”€â”€ scraper_facebook.py      # Scraper Facebook con Selenium + Groq AI
â”œâ”€â”€ groq_handler.py          # IntegraciÃ³n con API de Groq
â”œâ”€â”€ mapping.py               # GeneraciÃ³n de mapas interactivos
â”œâ”€â”€ requirements.txt         # Dependencias del proyecto
â”œâ”€â”€ .gitignore              # Archivos ignorados en git
â”œâ”€â”€ cookies.json            # (Opcional) Cookies de Facebook para login
â”œâ”€â”€ README.md               # Este archivo
â”œâ”€â”€ COMMITS.md              # GuÃ­a de commits con gitmojis
â””â”€â”€ QUICK_START.md          # GuÃ­a rÃ¡pida de inicio
```

### DescripciÃ³n de MÃ³dulos

#### `main.py`
- Interfaz web con Streamlit
- OrquestaciÃ³n del flujo completo de anÃ¡lisis
- Manejo de estado y sesiones
- VisualizaciÃ³n de resultados

#### `data_processing.py`
- `load_and_clean_data()` - Carga y limpia CSV con detecciÃ³n automÃ¡tica de separador
- `filter_by_province()` - Filtrado con normalizaciÃ³n de texto
- `detect_libraries()` - Detecta librerÃ­as por CIIU y palabras clave
- `geocode_one()` - Geocodifica con validaciÃ³n de provincia por cantÃ³n/parroquia
- `geocode_libraries()` - GeocodificaciÃ³n masiva con validaciÃ³n estricta
- `build_books_ranking_from_libraries()` - Ranking multi-fuente con cascada de scrapers

#### `scraper_google.py`
- `buscar_en_google()` - BÃºsqueda en DuckDuckGo (HTML, sin API)
- `clasificar_links()` - Filtra resultados a solo librerÃ­as
- `extraer_catalogo()` - Extrae tÃ­tulos de libros de sitios web
- `buscar()` - FunciÃ³n principal que combina todo
- âš¡ **Funciona sin FastAPI** - Importable directamente

#### `scraper_facebook.py`
- `configurar_selenium()` - Setup de Chrome WebDriver
- `cargar_cookies()` - Mantiene sesiÃ³n de Facebook
- `extraer_posts()` - Extrae posts de pÃ¡ginas de Facebook
- `detectar_titulos_batch()` - Usa Groq AI para identificar tÃ­tulos de libros
- `extraer_libros_facebook()` - FunciÃ³n principal
- âš¡ **Funciona sin FastAPI** - Importable directamente

#### `groq_handler.py`
- `init_groq_client()` - Inicializa cliente Groq
- `explain_best_seller()` - Explica por quÃ© un libro es popular
- `summarize_analysis()` - Genera resumen del mercado editorial
- Modelo: `llama-3.3-70b-versatile`

#### `mapping.py`
- `create_map_html()` - Genera mapas interactivos con Folium
- ValidaciÃ³n doble de provincia (columna + geocodificaciÃ³n)
- Marcadores con informaciÃ³n detallada

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Sistema de Scrapers en Cascada

El sistema intenta **4 niveles de extracciÃ³n** para cada librerÃ­a:

```python
# Nivel 1: Web scraping directo
google_search_first_result() + extraer_catalogo_web()

# Nivel 2: Scraper Google (DuckDuckGo)
from scraper_google import buscar
resultado = buscar(nombre, "Ecuador")

# Nivel 3: Scraper Facebook
from scraper_facebook import extraer_libros_facebook
resultado = extraer_libros_facebook(url, groq_key)

# Nivel 4: Fallback simulado
_generar_libros_fallback()  # TÃ­tulos realistas
```

### Variables de SesiÃ³n Streamlit
- `geoapify` - API Key de Geoapify
- `groq` - API Key de Groq
- `df` - DataFrame original cargado
- `filtered_df` - Filtrado por provincia
- `libraries_df` - LibrerÃ­as detectadas
- `geocoded_df` - Con coordenadas validadas
- `map_html` - Mapa generado

### ParÃ¡metros Personalizables

**En `data_processing.py`:**
```python
# CIIUs de librerÃ­as
LIBRARY_CIIUS = ["G4761", "G4762", ...]

# Palabras clave
LIBRARY_KEYWORDS = ["librer", "book", "editorial", ...]

# Libros de fallback
LIBROS_FALLBACK = ["El Quijote", "Cien aÃ±os de soledad", ...]
```

**En `scraper_google.py`:**
```python
# Excluir papelerÃ­as
EXCLUIR = ["papeler", "utiles", "escolar", ...]

# Incluir solo libros
INCLUIR = ["libr", "book", "editorial", ...]
```

**En `scraper_facebook.py`:**
```python
# ConfiguraciÃ³n Selenium
cantidad_posts = 10  # Posts a extraer
tiempo_scroll = 30   # Segundos de scroll
```

---

## ğŸ“Š Salidas y Resultados

### Tablas de Datos
- **LibrerÃ­as detectadas** - Nombre, ubicaciÃ³n, CIIU
- **EstadÃ­sticas por cantÃ³n/parroquia** - DistribuciÃ³n geogrÃ¡fica
- **Ranking de libros** - TÃ­tulos mÃ¡s repetidos

### Visualizaciones
- **Mapa interactivo** - UbicaciÃ³n de todas las librerÃ­as
- **GrÃ¡ficos estadÃ­sticos** - DistribuciÃ³n por zona

### AnÃ¡lisis de IA
- **ExplicaciÃ³n de best-sellers** - Por quÃ© ciertos libros lideran
- **Resumen de mercado** - Tendencias y patrones
- **EvaluaciÃ³n de piraterÃ­a** - Riesgos por tÃ­tulo

---

## ğŸ› Troubleshooting

### Error: "Invalid API Key"
**SoluciÃ³n:**
- Verifica tu clave en [console.groq.com](https://console.groq.com/) o [geoapify.com](https://www.geoapify.com/)
- Elimina espacios en blanco al copiar/pegar
- AsegÃºrate de usar las variables correctas: `GEOAPIFY_API_KEY` y `GROQ_API_KEY`

### Error: "Could not geocode address"
**SoluciÃ³n:**
- Verifica crÃ©ditos en tu cuenta de Geoapify
- El sistema valida por cantÃ³n/parroquia - algunas direcciones pueden fallar
- Los resultados fuera de provincia se filtran automÃ¡ticamente

### Scraper Google no funciona
**SoluciÃ³n:**
- Verifica conexiÃ³n a internet
- DuckDuckGo puede bloquear temporalmente por exceso de requests
- Espera 1-2 minutos y reintenta
- El sistema tiene fallback automÃ¡tico

### Scraper Facebook no extrae posts
**SoluciÃ³n:**
- Necesitas `cookies.json` con sesiÃ³n activa de Facebook
- Instala dependencias: `pip install selenium webdriver-manager`
- Chrome debe estar instalado en el sistema
- Si falla, el sistema usa fallback automÃ¡ticamente

### AplicaciÃ³n lenta
**Causas normales:**
- Web scraping toma 1-2 segundos por librerÃ­a
- GeocodificaciÃ³n con validaciÃ³n es mÃ¡s lenta pero precisa
- Groq AI puede tardar 2-5 segundos por anÃ¡lisis

**Optimizaciones:**
- Reduce `max_librerias` en el cÃ³digo (default: 5)
- Usa datasets filtrados previamente
- El cachÃ© de Streamlit ya estÃ¡ activo

### CSV no se carga
**SoluciÃ³n:**
- Verifica formato vÃ¡lido (sin filas corruptas)
- Columnas requeridas: `NOMBRE_FANTASIA_COMERCIAL`, `DESCRIPCION_PROVINCIA_EST`
- El sistema detecta separador automÃ¡ticamente (`,`, `;`, `|`, `\t`)
- Prueba con encoding UTF-8

### Mapa no muestra todas las librerÃ­as
**Es intencional:**
- El sistema **valida estrictamente** por provincia
- Solo muestra librerÃ­as cuyas coordenadas estÃ©n dentro de la provincia seleccionada
- Geoapify puede devolver resultados de otras provincias - se filtran automÃ¡ticamente

---

## ğŸš¢ Despliegue

### En Streamlit Cloud (Gratuito)
```bash
# 1. Pushea a GitHub
git push origin main

# 2. Ve a https://streamlit.io/cloud
# 3. Conecta tu repositorio
# 4. Crea un secreto con tus API Keys en los settings
```

### En Servidor Personal
```bash
# Instala supervisor o similar para mantener el proceso vivo
pip install gunicorn
streamlit run main.py --server.port 8501 &
```

---

## ğŸ“ Dependencias

| LibrerÃ­a | VersiÃ³n | Uso |
|----------|---------|-----|
| streamlit | latest | Framework web interactivo |
| pandas | latest | Procesamiento y anÃ¡lisis de datos |
| requests | latest | HTTP requests para APIs y scraping |
| beautifulsoup4 | latest | Parsing HTML para web scraping |
| folium | latest | Mapas interactivos con Leaflet |
| branca | latest | Soporte visual de mapas |
| groq | latest | API de IA (LLaMA 3.3 70B) |
| selenium | latest | AutomatizaciÃ³n de navegador |
| webdriver-manager | latest | GestiÃ³n automÃ¡tica de drivers |
| unidecode | latest | NormalizaciÃ³n de texto |

**InstalaciÃ³n completa:**
```bash
pip install streamlit pandas requests beautifulsoup4 folium branca groq selenium webdriver-manager unidecode
```

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:
1. Fork el repositorio
2. Crea una rama (`git checkout -b feature/mejora`)
3. Commit tus cambios (`git commit -m 'AÃ±ade mejora'`)
4. Push a la rama (`git push origin feature/mejora`)
5. Abre un Pull Request

---


## ğŸ“ Contacto y Soporte

Si encuentras problemas:
- Abre un issue en GitHub
- Revisa la secciÃ³n de Troubleshooting
- Consulta la documentaciÃ³n de las APIs externas

---

## ğŸ“ Casos de Uso

âœ… **AnÃ¡lisis de mercado editorial** - Estudia distribuciÃ³n y tendencias por provincia
âœ… **InvestigaciÃ³n acadÃ©mica** - Dataset del SRI + anÃ¡lisis geoespacial
âœ… **DetecciÃ³n de oportunidades** - Identifica zonas con baja cobertura
âœ… **Estudio de piraterÃ­a** - EvalÃºa riesgos por tÃ­tulo y regiÃ³n
âœ… **ExpansiÃ³n comercial** - Planifica apertura de nuevas librerÃ­as
âœ… **Benchmarking competitivo** - Compara catÃ¡logos entre competidores
âœ… **AnÃ¡lisis cultural** - Estudia patrones de lectura por regiÃ³n

---

## ğŸ”„ Flujo Completo del Sistema

```mermaid
graph TD
    A[Cargar CSV SRI] --> B[Filtrar por Provincia]
    B --> C[Detectar LibrerÃ­as CIIU + Keywords]
    C --> D[Geocodificar con Geoapify]
    D --> E[Validar Provincia CantÃ³n/Parroquia]
    E --> F[Generar Mapa Interactivo]
    
    F --> G[Extraer CatÃ¡logos]
    G --> H{Web Scraping}
    H -->|âœ… Ã‰xito| M[Ranking de Libros]
    H -->|âŒ Falla| I{Scraper Google}
    I -->|âœ… Ã‰xito| M
    I -->|âŒ Falla| J{Scraper Facebook}
    J -->|âœ… Ã‰xito| M
    J -->|âŒ Falla| K[Fallback Simulado]
    K --> M
    
    M --> N[AnÃ¡lisis Groq AI]
    N --> O[Best-seller Explanation]
    N --> P[Market Summary]
    N --> Q[Piracy Assessment]
```

---

## ğŸš€ Roadmap Futuro

- [ ] IntegraciÃ³n con mÃ¡s fuentes de datos (Mercado Libre, Amazon)
- [ ] Dashboard de mÃ©tricas en tiempo real
- [ ] ExportaciÃ³n de reportes en PDF
- [ ] API REST para consultas programÃ¡ticas
- [ ] Sistema de alertas por cambios en el mercado
- [ ] AnÃ¡lisis predictivo de tendencias

---

**Ãšltima actualizaciÃ³n:** 10 de Diciembre de 2025

Â¡Disfruta analizando el mercado de librerÃ­as ecuatoriano! ğŸ“šğŸ‡ªğŸ‡¨âœ¨
